# app.py â€” Bassam Brain (Ø°ÙƒØ§Ø¡ Ù…Ø­Ù„ÙŠ + Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
import pathlib, re, json, time
from typing import List, Dict, Set, Tuple

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ù…Ù„Ø®Øµ
from core.search_web import web_search, summarize_snippets
from core.compose_answer import compose_answer_ar

app = FastAPI(title="Bassam Brain â€” Ù…Ø­Ù„ÙŠ + Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø°ÙƒÙŠ")

# ========= Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª =========
DATA_DIR = pathlib.Path("data"); DATA_DIR.mkdir(exist_ok=True)
NOTES_DIR = DATA_DIR / "notes"; NOTES_DIR.mkdir(exist_ok=True)
DICT_DIR = DATA_DIR / "dict"; DICT_DIR.mkdir(exist_ok=True)

KB_FILE = NOTES_DIR / "knowledge.txt"
LOG_FILE = DATA_DIR / "log.jsonl"
TYPOS_FILE = DICT_DIR / "typos.tsv"
SYN_FILE = DICT_DIR / "synonyms.txt"

# Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
if not KB_FILE.exists():
    KB_FILE.write_text("Ø³Ø¤Ø§Ù„: Ù…Ø§ ÙÙˆØ§Ø¦Ø¯ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©ØŸ\nØ¬ÙˆØ§Ø¨: Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ØªÙˆØ³Ù‘Ø¹ Ø§Ù„Ù…Ø¯Ø§Ø±Ùƒ ÙˆØªØ²ÙŠØ¯ Ø§Ù„Ø«Ù‚Ø§ÙØ©.\n---\n", encoding="utf-8")

# ========= Ø£Ø¯ÙˆØ§Øª Ù„ØºÙˆÙŠØ© =========
from rapidfuzz import fuzz, process
from rank_bm25 import BM25Okapi
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

AR_DIAC = re.compile(r'[\u064B-\u0652]')
TOKEN_RE = re.compile(r'[A-Za-z\u0621-\u064A0-9]+')

def normalize_ar(s: str) -> str:
    s = s or ""
    s = AR_DIAC.sub('', s)
    s = s.replace('Ø£','Ø§').replace('Ø¥','Ø§').replace('Ø¢','Ø§')
    s = s.replace('Ø©','Ù‡').replace('Ù‰','ÙŠ').replace('Ø¤','Ùˆ').replace('Ø¦','ÙŠ')
    s = re.sub(r'\s+',' ', s).strip()
    return s

def ar_tokens(s: str) -> List[str]:
    return TOKEN_RE.findall(normalize_ar(s))

def load_qa() -> List[dict]:
    text = KB_FILE.read_text(encoding='utf-8') if KB_FILE.exists() else ""
    blocks = [b.strip() for b in text.split('---') if b.strip()]
    qa = []
    for b in blocks:
        m1 = re.search(r'Ø³Ø¤Ø§Ù„\s*:\s*(.+)', b)
        m2 = re.search(r'Ø¬ÙˆØ§Ø¨\s*:\s*(.+)', b)
        if m1 and m2:
            qa.append({"q": m1.group(1).strip(), "a": m2.group(1).strip()})
    return qa

QA_CACHE = load_qa()

def build_indexes(qa):
    docs_tokens = [ar_tokens(x["q"]) for x in qa]
    bm25 = BM25Okapi(docs_tokens)
    tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3,5))
    X = tfidf.fit_transform([normalize_ar(x["q"]) for x in qa])
    return bm25, tfidf, X

BM25, TFVEC, X_TFIDF = build_indexes(QA_CACHE)

def combined_search(q: str):
    qn = normalize_ar(q)
    scores = {}
    tokens = ar_tokens(qn)
    bm = BM25.get_scores(tokens)
    for i, s in enumerate(bm):
        scores[i] = s * 10
    for i, qa in enumerate(QA_CACHE):
        s = fuzz.token_set_ratio(qn, normalize_ar(qa["q"]))
        scores[i] = scores.get(i, 0) + s
    q_vec = TFVEC.transform([qn])
    cos = (X_TFIDF @ q_vec.T).ravel().toarray()
    for i, s in enumerate(cos):
        scores[i] = scores.get(i, 0) + s * 120
    best = sorted(scores.items(), key=lambda x: x[1], reverse=True)[0]
    return QA_CACHE[best[0]], best[1]

async def smart_answer(question: str) -> Tuple[str, dict]:
    if not question.strip():
        return "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙˆÙ„Ø§Ù‹.", {}
    doc, score = combined_search(question)
    if doc and score >= 140:
        return doc["a"], {"mode": "local"}
    if doc and score >= 90:
        return f"{doc['a']}\n\n(â„¹ï¸ Ø£Ù‚Ø±Ø¨ Ø³Ø¤Ø§Ù„ Ù…Ø´Ø§Ø¨Ù‡: Â«{doc['q']}Â»)", {"mode": "similar"}

    try:
        results = await web_search(question, max_results=8)
        if results:
            comp = compose_answer_ar(question, results)
            return comp["answer"], {"mode": "web", "links": comp["links"]}
    except Exception:
        pass

    if doc:
        return f"Ø£Ù‚Ø±Ø¨ Ù…Ø§ Ù„Ø¯ÙŠ:\n{doc['q']}\nØ§Ù„Ø¬ÙˆØ§Ø¨: {doc['a']}", {"mode": "fallback"}
    return "Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯.", {"mode": "none"}

@app.get("/", response_class=HTMLResponse)
def home():
    return """<h2>ğŸ¤– Bassam Brain â€” Ù…Ø­Ù„ÙŠ + Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø°ÙƒÙŠ</h2>
<form method='post' action='/ask'>
<textarea name='q' placeholder='Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...' rows='4' cols='60'></textarea><br>
<button>Ø¥Ø±Ø³Ø§Ù„</button>
</form>"""

@app.post("/ask", response_class=HTMLResponse)
async def ask(request: Request):
    form = await request.form()
    q = form.get("q","")
    ans, meta = await smart_answer(q)
    links = meta.get("links", [])
    html_links = "<ul>" + "".join([f"<li><a href='{u}' target='_blank'>{u}</a></li>" for u in links]) + "</ul>" if links else ""
    return f"<h3>Ø³Ø¤Ø§Ù„Ùƒ:</h3><p>{q}</p><h3>Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:</h3><p>{ans.replace(chr(10),'<br>')}</p>{html_links}<br><a href='/'>Ø±Ø¬ÙˆØ¹</a>"
