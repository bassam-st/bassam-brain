# app.py â€” Bassam Brain (Ù†Ø³Ø®Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø®ÙÙŠÙØ© Ù…Ø¹ Ø°Ø§ÙƒØ±Ø© ÙˆRAG)
from fastapi import FastAPI, Request, Form, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse
import os, httpx, json, time, pathlib, re

app = FastAPI(title="Bassam Brain â€“ Lite")

# ====== Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© ======
DATA_DIR   = pathlib.Path("data"); DATA_DIR.mkdir(exist_ok=True)
NOTES_DIR  = DATA_DIR / "notes";   NOTES_DIR.mkdir(exist_ok=True)
LOG_FILE   = DATA_DIR / "log.jsonl"             # ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©/Ø§Ù„Ø£Ø¬ÙˆØ¨Ø©
FEED_FILE  = DATA_DIR / "feedback_pool.jsonl"   # Ø£Ù…Ø«Ù„Ø© Ù…Ù…ØªØ§Ø²Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ø§Ø­Ù‚Ù‹Ø§
KB_FILE    = NOTES_DIR / "knowledge.txt"        # Ø¯ÙØªØ± Ù…Ø¹Ø±ÙØ© Ø¨Ø³ÙŠØ·
if not KB_FILE.exists():
    KB_FILE.write_text("Ø£Ø¶Ù Ù‡Ù†Ø§ ÙÙ‚Ø±Ø§Øª Ù‚ØµÙŠØ±Ø© Ù…Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ Ø§Ù„Ù…Ù‡Ù…Ø©.\n", encoding="utf-8")

# ====== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ø¬Ù‡Ø© Ù†Ù…ÙˆØ°Ø¬ Ø®Ø§Ø±Ø¬ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ======
# ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡Ø§ Ù…Ù† Environment Variables ÙÙŠ Render
UPSTREAM_API_URL   = os.getenv("UPSTREAM_API_URL", "https://api.freegpt4.ai/v1/chat/completions")
UPSTREAM_API_KEY   = os.getenv("UPSTREAM_API_KEY", "")   # Ø¥Ù† ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨
UPSTREAM_MODEL     = os.getenv("UPSTREAM_MODEL", "gpt-4o-mini")  # Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø­Ø³Ø¨ Ù…Ø²ÙˆØ¯Ùƒ

# ====== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ======
def clamp(s: str, n: int) -> str:
    s = (s or "").strip()
    return s if len(s) <= n else s[:n]

def pick_relevant(text: str, query: str, k: int = 6):
    """Ø§Ø®ØªÙŠØ§Ø± Ø¬ÙÙ…Ù„ Ù‚Ø±ÙŠØ¨Ø© Ø¬Ø¯Ù‹Ø§ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª (RAG Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† Ù…ÙƒØªØ¨Ø§Øª)."""
    sents = re.split(r"[\.!\?\nâ€¦]+", text)
    qtok = set(re.findall(r"\w+", query))
    scored = []
    for s in sents:
        t = s.strip()
        if not t: continue
        stok = set(re.findall(r"\w+", t))
        score = len(qtok & stok)
        if score: scored.append((score, t))
    scored.sort(reverse=True)
    return [t for _, t in scored[:k]]

def build_context(question: str, extra: str) -> str:
    kb = KB_FILE.read_text(encoding="utf-8")
    rel = pick_relevant(kb, question, k=6)
    ctx = ""
    if rel:
        ctx += "Ù…Ù‚ØªØ·ÙØ§Øª Ù…Ø¹Ø±ÙØ©:\n- " + "\n- ".join(rel) + "\n\n"
    if extra:
        ctx += f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n{extra}\n\n"
    return ctx

async def call_model(prompt: str, temperature: float = 0.7, max_tokens: int = 180) -> str:
    """
    ÙŠØ³ØªØ¯Ø¹ÙŠ Ø£ÙŠ ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø´ÙƒÙ„ OpenAI Chat Completions.
    Ø¥Ù† ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨ØŒ ÙŠØ±Ø¬Ø¹ Ø±Ø¯Ù‹Ø§ Ø¨Ø³ÙŠØ·Ù‹Ø§ Ø¨Ø¯Ù„ Ø§Ù„Ø§Ù†Ù‡ÙŠØ§Ø±.
    """
    headers = {"Content-Type": "application/json"}
    if UPSTREAM_API_KEY:
        headers["Authorization"] = f"Bearer {UPSTREAM_API_KEY}"

    payload = {
        "model": UPSTREAM_MODEL,
        "messages": [
            {"role": "system", "content": "Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯Ù‚Ø© ÙˆØ§Ø®ØªØµØ§Ø±. Ø¥Ù† Ù„Ù… ØªÙƒÙ† ÙˆØ§Ø«Ù‚Ù‹Ø§ Ù‚Ù„: Ù„Ø§ Ø£Ø¹Ù„Ù…."},
            {"role": "user", "content": prompt}
        ],
        "temperature": float(temperature),
        "max_tokens": int(max_tokens)
    }

    try:
        async with httpx.AsyncClient(timeout=40) as client:
            r = await client.post(UPSTREAM_API_URL, headers=headers, json=payload)
            r.raise_for_status()
            data = r.json()
            msg = (data.get("choices") or [{}])[0].get("message", {}).get("content")
            if not msg:
                raise ValueError("no content")
            return msg.strip()
    except Exception as e:
        # Ùallback Ù…Ù‡Ø°Ø¨ Ø¨Ø¯Ù„ INTERNAL ERROR
        return f"Ø¹Ø°Ø±Ù‹Ø§ØŒ ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ Ø§Ù„Ø¢Ù†. Ø³Ø¨Ø¨ ØªÙ‚Ù†ÙŠ: {type(e).__name__}. Ø¬Ø±Ù‘Ø¨ Ø«Ø§Ù†ÙŠØ©."

# ====== ØµÙØ­Ø§Øª ÙˆØªØ¬Ø§Ø±Ø¨ ======
@app.get("/", response_class=HTMLResponse)
def home():
    return """
    <div style="max-width:720px;margin:24px auto;font-family:system-ui">
      <h1>ğŸ¤– Bassam Brain â€” Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©</h1>
      <form method="post" action="/ask">
        <textarea name="q" rows="5" style="width:100%" placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..."></textarea>
        <details style="margin:8px 0">
          <summary>Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)</summary>
          <textarea name="extra" rows="4" style="width:100%" placeholder="Ø£Ù„ØµÙ‚ Ù†ØµÙ‹Ø§ Ø£Ùˆ Ù†Ù‚Ø§Ø·Ù‹Ø§ ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"></textarea>
        </details>
        <label>Temperature</label>
        <input type="number" step="0.1" name="temperature" value="0.7" style="width:90px">
        <label style="margin-inline-start:8px">Max tokens</label>
        <input type="number" name="max_new_tokens" value="180" style="width:100px">
        <div><button style="margin-top:10px">Ø¥Ø±Ø³Ø§Ù„</button></div>
      </form>
    </div>
    """

@app.post("/ask", response_class=HTMLResponse)
async def ask(request: Request):
    form = await request.form()
    q     = clamp(form.get("q",""), 1000)
    extra = clamp(form.get("extra",""), 3000)
    temp  = float(form.get("temperature", 0.7))
    mx    = int(form.get("max_new_tokens", 180))

    ctx   = build_context(q, extra)
    prompt = f"""{ctx}Ø§Ù„Ø³Ø¤Ø§Ù„: {q}
Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø§Ù„Ù…Ø®ØªØµØ± Ø¨Ø¯Ù‚Ø©:"""
    ans = await call_model(prompt, temperature=temp, max_tokens=mx)

    # Ø³Ø¬Ù„ ÙÙŠ log.jsonl
    rec = {"ts": int(time.time()), "instruction": q, "input": extra, "output": ans}
    with open(LOG_FILE, "a", encoding="utf-8") as f: f.write(json.dumps(rec, ensure_ascii=False)+"\n")

    return f"<div style='max-width:720px;margin:24px auto;font-family:system-ui'>" \
           f"<p><b>Ø³Ø¤Ø§Ù„Ùƒ:</b> {q}</p><p><b>Ø§Ù„Ø¬ÙˆØ§Ø¨:</b> {ans}</p>" \
           f"<form method='post' action='/save'><input type='hidden' name='q' value='{q}'>" \
           f"<input type='hidden' name='a' value='{ans}'><button>ğŸ‘ Ø­ÙØ¸ ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨</button></form>" \
           f"<p><a href='/'>â—€ Ø±Ø¬ÙˆØ¹</a></p></div>"

@app.post("/save", response_class=HTMLResponse)
async def save(request: Request):
    form = await request.form()
    rec = {"ts": int(time.time()), "instruction": form.get("q",""), "input": "", "output": form.get("a","")}
    with open(FEED_FILE, "a", encoding="utf-8") as f: f.write(json.dumps(rec, ensure_ascii=False)+"\n")
    return "<p>âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø«Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨.</p><p><a href='/'>â—€ Ø±Ø¬ÙˆØ¹</a></p>"

# ====== ÙˆØ§Ø¬Ù‡Ø§Øª API ======
@app.get("/ready")
def ready():
    return {"ok": True}

@app.post("/generate")
async def generate(request: Request):
    body = await request.json()
    q     = clamp(body.get("question",""), 1000)
    extra = clamp(body.get("extra",""), 3000)
    temp  = float(body.get("temperature", 0.7))
    mx    = int(body.get("max_new_tokens", 180))

    ctx = build_context(q, extra)
    prompt = f"""{ctx}Ø§Ù„Ø³Ø¤Ø§Ù„: {q}
Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø§Ù„Ù…Ø®ØªØµØ± Ø¨Ø¯Ù‚Ø©:"""
    ans = await call_model(prompt, temperature=temp, max_tokens=mx)

    # Ø³Ø¬Ù„
    rec = {"ts": int(time.time()), "instruction": q, "input": extra, "output": ans}
    with open(LOG_FILE, "a", encoding="utf-8") as f: f.write(json.dumps(rec, ensure_ascii=False)+"\n")
    return JSONResponse({"ok": True, "answer": ans})

@app.post("/feedback")
async def feedback(request: Request):
    data = await request.json()
    if not bool(data.get("good", True)):
        return {"ok": True}
    rec = {
        "ts": int(time.time()),
        "instruction": data.get("q",""),
        "input": data.get("extra",""),
        "output": data.get("a","")
    }
    with open(FEED_FILE, "a", encoding="utf-8") as f: f.write(json.dumps(rec, ensure_ascii=False)+"\n")
    return {"ok": True}

@app.get("/export/feedback")
def export_feedback():
    if not FEED_FILE.exists(): FEED_FILE.write_text("", encoding="utf-8")
    return FileResponse(path=str(FEED_FILE), media_type="text/plain", filename="feedback_pool.jsonl")
